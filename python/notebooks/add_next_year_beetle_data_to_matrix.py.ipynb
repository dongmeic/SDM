{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../models')\n",
    "\n",
    "import model_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/cluster/year/'\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2013 # Cannot add next year's data to 2014, so 2013 is last here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (529623, 24)\n",
      "X_valid: (176541, 24)\n",
      "X_test: (176541, 24)\n",
      "y_train: (529623, 1)\n",
      "y_valid: (176541, 1)\n",
      "y_test: (176541, 1)\n"
     ]
    }
   ],
   "source": [
    "[[X_train, y_train], \n",
    " [X_valid, y_valid], \n",
    " [X_test, y_test]] = util.load_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882705, 24)\n",
      "(882705, 25)\n"
     ]
    }
   ],
   "source": [
    "data = X_train.append(X_valid).append(X_test)\n",
    "y = y_train.append(y_valid).append(y_test)\n",
    "data['beetle'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_yearly_data(data, year):\n",
    "    dat = data.copy()\n",
    "    year_data = dat.loc[dat.year == year, :]\n",
    "    y_year = pd.DataFrame(year_data['beetle'])\n",
    "    X_year = year_data.drop(['beetle'], axis=1)\n",
    "    return X_year, y_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_sets(data_sets):\n",
    "    X, y = data_sets[0]\n",
    "    for i in range(1, len(data_sets)):\n",
    "        next_X, next_y = data_sets[i]\n",
    "        X = X.append(next_X)\n",
    "        y = y.append(next_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_new_data_sets(data):\n",
    "    TEST = 2\n",
    "    VALID = 2\n",
    "    TRAIN = 9\n",
    "    yearly_data = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        X, y = make_yearly_data(data, year)\n",
    "        yearly_data.append([X, y])\n",
    "    assert TRAIN + VALID + TEST == len(yearly_data) - 1\n",
    "    \n",
    "    with_beetle_data = []\n",
    "    for i in range(len(yearly_data) - 1):\n",
    "        x1, y1 = yearly_data[i]\n",
    "        x2, y2 = yearly_data[i + 1]\n",
    "        assert list(x1.x) == list(x2.x)\n",
    "        assert list(x1.y) == list(x2.y)\n",
    "        x1['next_year_beetle'] = y2['beetle']\n",
    "        with_beetle_data.append([x1, y1])\n",
    "        \n",
    "    test = with_beetle_data[:TEST]\n",
    "    valid = with_beetle_data[TEST : TEST + VALID]\n",
    "    train = with_beetle_data[TEST + VALID:]\n",
    "    \n",
    "    X_test, y_test = merge_sets(test)\n",
    "    X_valid, y_valid = merge_sets(valid)\n",
    "    X_train, y_train = merge_sets(train)\n",
    "    \n",
    "    return [[X_train, y_train], [X_valid, y_valid], [X_test, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[[X_train, y_train], \n",
    " [X_valid, y_valid], \n",
    " [X_test, y_test]] = make_new_data_sets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529623, 25) (529623, 1)\n",
      "(117694, 25) (117694, 1)\n",
      "(117694, 25) (117694, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xy(xy, path, suffix):\n",
    "    X, y = xy\n",
    "    X.to_csv(path + 'X_' + suffix + '.csv')\n",
    "    y.to_csv(path + 'y_' + suffix + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_xy([X_train, y_train], DATA_DIR, 'train_full')\n",
    "save_xy([X_valid, y_valid], DATA_DIR, 'valid_full')\n",
    "save_xy([X_test, y_test], DATA_DIR, 'test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tensor2000.pkl.bz2',\n",
       " 'tensor2001.pkl.bz2',\n",
       " 'tensor2002.pkl.bz2',\n",
       " 'tensor2003.pkl.bz2',\n",
       " 'tensor2004.pkl.bz2',\n",
       " 'tensor2005.pkl.bz2',\n",
       " 'tensor2006.pkl.bz2',\n",
       " 'tensor2007.pkl.bz2',\n",
       " 'tensor2008.pkl.bz2',\n",
       " 'tensor2009.pkl.bz2',\n",
       " 'tensor2010.pkl.bz2',\n",
       " 'tensor2011.pkl.bz2',\n",
       " 'tensor2012.pkl.bz2',\n",
       " 'tensor2013.pkl.bz2',\n",
       " 'tensor2014.pkl.bz2',\n",
       " 'tensor20_2000.pkl.bz2',\n",
       " 'tensor20_2001.pkl.bz2',\n",
       " 'tensor20_2002.pkl.bz2',\n",
       " 'tensor20_2003.pkl.bz2',\n",
       " 'tensor20_2004.pkl.bz2',\n",
       " 'tensor20_2005.pkl.bz2',\n",
       " 'tensor20_2006.pkl.bz2',\n",
       " 'tensor20_2007.pkl.bz2',\n",
       " 'tensor20_2008.pkl.bz2',\n",
       " 'tensor20_2009.pkl.bz2',\n",
       " 'tensor20_2010.pkl.bz2',\n",
       " 'tensor20_2011.pkl.bz2',\n",
       " 'tensor20_2012.pkl.bz2',\n",
       " 'tensor20_2013.pkl.bz2',\n",
       " 'weights.bestNN.hdf5',\n",
       " 'X_big_test.csv',\n",
       " 'X_big_train.csv',\n",
       " 'X_big_valid.csv',\n",
       " 'X_test.csv',\n",
       " 'X_test_full.csv',\n",
       " 'X_train.csv',\n",
       " 'X_train_full.csv',\n",
       " 'X_valid.csv',\n",
       " 'X_valid_full.csv',\n",
       " 'y_big_test.csv',\n",
       " 'y_big_train.csv',\n",
       " 'y_big_valid.csv',\n",
       " 'y_matrix2000.pkl.bz2',\n",
       " 'y_matrix2001.pkl.bz2',\n",
       " 'y_matrix2002.pkl.bz2',\n",
       " 'y_matrix2003.pkl.bz2',\n",
       " 'y_matrix2004.pkl.bz2',\n",
       " 'y_matrix2005.pkl.bz2',\n",
       " 'y_matrix2006.pkl.bz2',\n",
       " 'y_matrix2007.pkl.bz2',\n",
       " 'y_matrix2008.pkl.bz2',\n",
       " 'y_matrix2009.pkl.bz2',\n",
       " 'y_matrix2010.pkl.bz2',\n",
       " 'y_matrix2011.pkl.bz2',\n",
       " 'y_matrix2012.pkl.bz2',\n",
       " 'y_matrix2013.pkl.bz2',\n",
       " 'y_matrix2014.pkl.bz2',\n",
       " 'y_test.csv',\n",
       " 'y_test_full.csv',\n",
       " 'y_train.csv',\n",
       " 'y_train_full.csv',\n",
       " 'y_valid.csv',\n",
       " 'y_valid_full.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
